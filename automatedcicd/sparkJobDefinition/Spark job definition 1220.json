{
	"name": "Spark job definition 1220",
	"properties": {
		"targetBigDataPool": {
			"referenceName": "zhao",
			"type": "BigDataPoolReference"
		},
		"requiredSparkVersion": "3.1",
		"language": "python",
		"jobProperties": {
			"name": "Spark job definition 1220",
			"file": "abfss://default@honghaigen2.dfs.core.windows.net/synapse/workspaces/bdbj20211220ws/batchjobs/Spark%20job%20definition%201220/copy_opendataset_to_spark_table.py",
			"conf": {
				"spark.dynamicAllocation.enabled": "true",
				"spark.dynamicAllocation.minExecutors": "1",
				"spark.dynamicAllocation.maxExecutors": "1",
				"spark.autotune.trackingId": "be5b1469-36c5-4eb4-ac76-1164f1a059fe"
			},
			"args": [],
			"jars": [],
			"files": [],
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 1
		}
	}
}